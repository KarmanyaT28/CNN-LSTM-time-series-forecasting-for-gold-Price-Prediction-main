{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "f87398b2de8e90719949ed00c7b022e62357d5ca27b768fb93eb54116fa5b864"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.10 64-bit ('CNN-LSTM_gold_price-o7kuqWqa': pipenv)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "CNN-LSTM model for Gold Price",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "92xYjTYft-Ks"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, roc_curve, auc\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, InputLayer\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMyXOyw9ankY"
      },
      "source": [
        "## Reading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdjRYQQft-Kv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "115e123b-6db8-4bd7-cc61-77e170f9b4ff"
      },
      "source": [
        "# Reading the dataset\n",
        "data_csv = \"/content/dataset.csv\"\n",
        "df = pd.read_csv(data_csv)\n",
        "print('Dataset shape: ', df.shape)\n",
        "print(df.dtypes)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape:  (1089, 7)\n",
            "Date          object\n",
            "Open         float64\n",
            "High         float64\n",
            "Low          float64\n",
            "Close        float64\n",
            "Adj Close    float64\n",
            "Volume       float64\n",
            "dtype: object\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-12-31</td>\n",
              "      <td>1196.400024</td>\n",
              "      <td>1212.400024</td>\n",
              "      <td>1182.000000</td>\n",
              "      <td>1201.900024</td>\n",
              "      <td>1201.900024</td>\n",
              "      <td>124.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2014-01-02</td>\n",
              "      <td>1204.300049</td>\n",
              "      <td>1227.300049</td>\n",
              "      <td>1204.300049</td>\n",
              "      <td>1225.000000</td>\n",
              "      <td>1225.000000</td>\n",
              "      <td>209.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>1221.699951</td>\n",
              "      <td>1239.000000</td>\n",
              "      <td>1221.699951</td>\n",
              "      <td>1238.400024</td>\n",
              "      <td>1238.400024</td>\n",
              "      <td>142.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2014-01-06</td>\n",
              "      <td>1232.800049</td>\n",
              "      <td>1247.000000</td>\n",
              "      <td>1221.900024</td>\n",
              "      <td>1237.800049</td>\n",
              "      <td>1237.800049</td>\n",
              "      <td>127.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2014-01-07</td>\n",
              "      <td>1239.300049</td>\n",
              "      <td>1242.400024</td>\n",
              "      <td>1226.300049</td>\n",
              "      <td>1229.400024</td>\n",
              "      <td>1229.400024</td>\n",
              "      <td>73.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date         Open         High  ...        Close    Adj Close  Volume\n",
              "0  2013-12-31  1196.400024  1212.400024  ...  1201.900024  1201.900024   124.0\n",
              "1  2014-01-02  1204.300049  1227.300049  ...  1225.000000  1225.000000   209.0\n",
              "2  2014-01-03  1221.699951  1239.000000  ...  1238.400024  1238.400024   142.0\n",
              "3  2014-01-06  1232.800049  1247.000000  ...  1237.800049  1237.800049   127.0\n",
              "4  2014-01-07  1239.300049  1242.400024  ...  1229.400024  1229.400024    73.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3wBSImUasd2"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKiveFibt-Kw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6f7ba5-c509-498f-8828-a31426bc1d7f"
      },
      "source": [
        "# Verifying null values and deleting name from dataset\n",
        "null_columns=df.columns[df.isnull().any()]\n",
        "print(df[df.isnull().any(axis=1)][null_columns].head())\n",
        "# Drop the lines with null values\n",
        "df = df.dropna()\n",
        "# Drop Date column\n",
        "# df.pop(\"Date\")\n",
        "\n",
        "print('Dataset shape: ', df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Open  High  Low  Close  Adj Close  Volume\n",
            "127   NaN   NaN  NaN    NaN        NaN     NaN\n",
            "230   NaN   NaN  NaN    NaN        NaN     NaN\n",
            "248   NaN   NaN  NaN    NaN        NaN     NaN\n",
            "515   NaN   NaN  NaN    NaN        NaN     NaN\n",
            "535   NaN   NaN  NaN    NaN        NaN     NaN\n",
            "Dataset shape:  (1081, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "oaE7zliQhh-z",
        "outputId": "5ec68944-ba63-4d9c-eaf9-18c8bc311209"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1081.000000</td>\n",
              "      <td>1081.000000</td>\n",
              "      <td>1081.000000</td>\n",
              "      <td>1081.000000</td>\n",
              "      <td>1081.000000</td>\n",
              "      <td>1081.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1239.990935</td>\n",
              "      <td>1245.948751</td>\n",
              "      <td>1234.181223</td>\n",
              "      <td>1240.121092</td>\n",
              "      <td>1240.121092</td>\n",
              "      <td>5710.888992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>72.099380</td>\n",
              "      <td>71.958409</td>\n",
              "      <td>72.366352</td>\n",
              "      <td>72.285649</td>\n",
              "      <td>72.285649</td>\n",
              "      <td>30312.863258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1053.699951</td>\n",
              "      <td>1062.000000</td>\n",
              "      <td>1046.199951</td>\n",
              "      <td>1050.800049</td>\n",
              "      <td>1050.800049</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1196.199951</td>\n",
              "      <td>1202.500000</td>\n",
              "      <td>1188.000000</td>\n",
              "      <td>1195.599976</td>\n",
              "      <td>1195.599976</td>\n",
              "      <td>41.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1251.000000</td>\n",
              "      <td>1256.000000</td>\n",
              "      <td>1244.800049</td>\n",
              "      <td>1250.800049</td>\n",
              "      <td>1250.800049</td>\n",
              "      <td>138.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1293.400024</td>\n",
              "      <td>1299.800049</td>\n",
              "      <td>1288.000000</td>\n",
              "      <td>1294.199951</td>\n",
              "      <td>1294.199951</td>\n",
              "      <td>415.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1386.099976</td>\n",
              "      <td>1391.400024</td>\n",
              "      <td>1372.199951</td>\n",
              "      <td>1379.000000</td>\n",
              "      <td>1379.000000</td>\n",
              "      <td>290889.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Open         High  ...    Adj Close         Volume\n",
              "count  1081.000000  1081.000000  ...  1081.000000    1081.000000\n",
              "mean   1239.990935  1245.948751  ...  1240.121092    5710.888992\n",
              "std      72.099380    71.958409  ...    72.285649   30312.863258\n",
              "min    1053.699951  1062.000000  ...  1050.800049       0.000000\n",
              "25%    1196.199951  1202.500000  ...  1195.599976      41.000000\n",
              "50%    1251.000000  1256.000000  ...  1250.800049     138.000000\n",
              "75%    1293.400024  1299.800049  ...  1294.199951     415.000000\n",
              "max    1386.099976  1391.400024  ...  1379.000000  290889.000000\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFxI1LjHt-Kx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64b00314-4a7f-4a36-c7ec-75aead05417c"
      },
      "source": [
        "print(\"Minimum: {}\\nMaximum: {}\\nMean: {}\\nMedian: {}\\nSD: {}\\nSkewness: {}\\nKurtosis: {}\".format(df[\"Low\"].min(), df[\"High\"].max(), \n",
        "df[\"Open\"].mean(), df[\"Open\"].median(), df[\"Open\"].std(), df[\"Open\"].skew(), df[\"Open\"].kurtosis()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum: 1046.199951\n",
            "Maximum: 1391.400024\n",
            "Mean: 1239.9909346142476\n",
            "Median: 1251.0\n",
            "SD: 72.09937994027125\n",
            "Skewness: -0.5455305158449637\n",
            "Kurtosis: -0.3520037164214358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8r2P7-st-Kx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "637c2385-e2f4-45cd-e479-91496441fc97"
      },
      "source": [
        "lastday_2017 = df.loc[df[\"Date\"]==\"2017-12-29\"].index.values[0]\n",
        "df = df[\"Open\"].values\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(df/10)\n",
        "plt.xlabel(\"Days\")\n",
        "plt.ylabel(\"Price (*10^-1)\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3RLcvdmaxJF"
      },
      "source": [
        "## Normalizing\n",
        "for homogenizing the variability and stability of the patterns and reducing exponential trend."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAQuUju3t-Ky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49a85299-dc2a-403b-bd1c-31cce821d1a4"
      },
      "source": [
        "# Transforming the dataset to ln scale\n",
        "df = np.log(df)\n",
        "\n",
        "# # Split dataset into train and test\n",
        "train_set = df[0:lastday_2017]\n",
        "test_set = df[lastday_2017:]\n",
        "print(\"Train: \", train_set.shape, \"Test: \", test_set.shape)\n",
        "lastday_2017"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:  (1007,) Test:  (74,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1007"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywhAxSYOt-Ky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "247a4124-880f-45b4-dc84-542c4ae3a787"
      },
      "source": [
        "print(train_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7.08707235 7.0936538  7.10799857 ... 7.1856143  7.18531127 7.17747701]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jhw5awIrcn0C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f96b939-7b02-49ba-b301-db893f9f8a7b"
      },
      "source": [
        "print(test_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7.1856143  7.18318761 7.19127875 7.19376093 7.19623705 7.19210683\n",
            " 7.19300939 7.19173051 7.19728568 7.21222074 7.21251572 7.20904434\n",
            " 7.19945424 7.19855748 7.20325674 7.20674814 7.19376093 7.19908067\n",
            " 7.1894696  7.18318761 7.18606862 7.1882617  7.18879031 7.19503731\n",
            " 7.20934026 7.21081845 7.206674   7.19052534 7.18690102 7.19142933\n",
            " 7.19668657 7.19421156 7.1818961  7.17808773 7.18105952 7.18803502\n",
            " 7.18659838 7.19900596 7.18901682 7.18295987 7.18493238 7.18984677\n",
            " 7.18705226 7.18295987 7.17785873 7.17732431 7.17862174 7.17961282\n",
            " 7.19037454 7.20281007 7.20674814 7.20117088 7.20414929 7.18841274\n",
            " 7.19067603 7.20072337 7.19428673 7.19556234 7.19029917 7.19518732\n",
            " 7.19683634 7.2004995  7.20874833 7.19736052 7.20117088 7.20637729\n",
            " 7.20303343 7.20682228 7.20228883 7.19593723 7.1902238  7.18841274\n",
            " 7.18212409 7.18182009]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMlPzpDot-Kz"
      },
      "source": [
        "## Labels of an LSTM network\n",
        "the LSTM network needs to predict the next day gold price closing value, this way a matrix of 2 dimensions will suffice for this problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIe_sbryt-K1"
      },
      "source": [
        "# Regression models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqK7SUkPdeK_"
      },
      "source": [
        "### Forward Feed Neural Network (FFNN)\n",
        "1 hidden layer with 3, 3 and 5 neurons for F = 4; 6 and 9, respectively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dcym40iRt-K1"
      },
      "source": [
        "# FFNN class\n",
        "class FFNN:\n",
        "    def __init__(self, input_dim, scaler=None):\n",
        "        self.scaler = scaler \n",
        "        optimizer = Adam() ## ADAM optimizer\n",
        "        ## if input dimension == 4 then hidden nodes = 3\n",
        "        ## else if input dimension == 6 then hidden nodes =5\n",
        "        h_n = 3 if input_dim == 4 or input_dim == 6 else 5\n",
        "        self.model = Sequential() ## sequetial model\n",
        "        self.model.add(Dense(h_n, input_dim=input_dim)) \n",
        "        self.model.add(Dense(1)) ## 1 dense layer\n",
        "        ## metrics used: mse, accuracy, mae\n",
        "        self.model.compile(loss=\"mean_squared_error\", optimizer=optimizer, metrics=[\"accuracy\", \"mean_absolute_error\"])\n",
        "    \n",
        "    def fit(self,x_train,y_train):\n",
        "        if self.scaler:\n",
        "            ## splitting into x and y\n",
        "            x_train = self.scaler.transform(x_train)\n",
        "            y_train = self.scaler.transform(y_train)\n",
        "\n",
        "        ## fitting the model\n",
        "        self.model.fit(x_train, y_train,verbose=0)\n",
        "\n",
        "    ## predict function\n",
        "    def predict(self, x_test):\n",
        "        if self.scaler:\n",
        "            x_test = self.scaler.transform(x_test)\n",
        "            \n",
        "        y_valid_pred = self.model.predict(x_test)\n",
        "        \n",
        "        if self.scaler:\n",
        "            y_valid_pred = self.scaler.transform(y_valid_pred)\n",
        "\n",
        "        return y_valid_pred.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fEwEMIOhpU9"
      },
      "source": [
        "## LSTM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9Hx-Ujeh6sr"
      },
      "source": [
        "- LSTM1 \n",
        "  - LSTM layer with 100 units\n",
        "- LSTM2 \n",
        "  - LSTM layer with 200 units\n",
        "- LSTM3 \n",
        "  - LSTM layer with 100 units\n",
        "  - LSTM layer with 50 units\n",
        "- LSTM4 \n",
        "  - LSTM layer with 100 units\n",
        "  - LSTM layer with 100 units\n",
        "  - Fully connected layer with 32 neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCqubft9t-K2"
      },
      "source": [
        "# LSTM class\n",
        "class PLSTM:\n",
        "    def __init__(self, input_shape, model_type, scaler=None):\n",
        "        self.scaler = scaler \n",
        "        optimizer = Adam() ## Adam Optimizer\n",
        "        self.model = Sequential() ## Sequential Model\n",
        "        self.h_n1 = 100 if model_type in [1,3,4] else 200 ## Hidden Nodes\n",
        "        return_seq = True if model_type>2 else False\n",
        "        self.model.add(LSTM(units=self.h_n1, input_shape=(input_shape[1], 1), return_sequences=return_seq))\n",
        "        if model_type>2:\n",
        "            self.h_n2 = 50 if model_type == 3 else 100\n",
        "            self.model.add(LSTM(units=self.h_n2)) ## LSTM layer\n",
        "            if type==4:\n",
        "                self.model.add(Dense(32)) ## Dense layer 32\n",
        "        self.model.add(Dense(1)) ## Dense Layer 1\n",
        "        self.model.compile(loss=\"mean_squared_error\", optimizer=optimizer, metrics=[\"accuracy\", \"mean_absolute_error\"])\n",
        "    \n",
        "    def fit(self,x_train,y_train):\n",
        "        if self.scaler:\n",
        "            x_train = self.scaler.transform(x_train)\n",
        "            y_train = self.scaler.transform(y_train)\n",
        "\n",
        "        # reshape the entry as a 3D matrix with samples, timestamps and lastly features\n",
        "        # instead of only samples and features as usual.\n",
        "        x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "        history = self.model.fit(x_train, y_train,epochs=50,batch_size=128,verbose=0)\n",
        "\n",
        "    def predict(self, x_test):\n",
        "        if self.scaler:\n",
        "            x_test = self.scaler.transform(x_test)\n",
        "            \n",
        "        x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "        y_valid_pred = self.model.predict(x_test)\n",
        "        \n",
        "        if self.scaler:\n",
        "            y_valid_pred = self.scaler.transform(y_valid_pred)\n",
        "\n",
        "        return y_valid_pred.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08ga1GLdhm2w"
      },
      "source": [
        "## CNN-LSTM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XY6z5rwiQWJ"
      },
      "source": [
        "- CNNLSTM1 \n",
        "  - Convolutional layer with 32 filters of size (2,)\n",
        "  - Convolutional layer with 64 filters of size (2,)\n",
        "  - Max pooling layer with size (2,)\n",
        "  - LSTM layer with 100 units\n",
        "- CNNLSTM2 \n",
        "  - Convolutional layer with 64 filters of size (2,)\n",
        "  - Convolutional layer with 128 filters of size (2,)\n",
        "  - Max pooling layer with size (2,)\n",
        "  - LSTM layer with 200 units\n",
        "  - Fully connected layer with 32 neurons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwQhuTr7ikrb"
      },
      "source": [
        "- Activation : relu\n",
        "- Convlulution 1D\n",
        "- MaxPooling Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIRJ_KYtt-K3"
      },
      "source": [
        "# CNN-LSTM class\n",
        "class CNNLSTM:\n",
        "    def __init__(self, input_shape, model_type, scaler=None):\n",
        "        self.scaler = scaler\n",
        "        optimizer = Adam()\n",
        "        self.model = Sequential()\n",
        "        self.h_n1 = 100 if model_type == 1 else 200\n",
        "        self.filter1 = 32 if model_type == 1 else 64\n",
        "        self.filter2 = 64 if model_type == 1 else 128\n",
        "        \n",
        "        self.model.add(Conv1D(self.filter1, 2,activation='relu',\n",
        "                       strides=1,\n",
        "                       padding='same',\n",
        "                       input_shape=(input_shape[1],\n",
        "                                   1)))\n",
        "\n",
        "        self.model.add(Conv1D(self.filter2, 2,\n",
        "                   activation='relu',\n",
        "                   strides=1,\n",
        "                   padding='same',\n",
        "                   input_shape=(input_shape[1],\n",
        "                                1)))\n",
        "\n",
        "        self.model.add(MaxPooling1D(pool_size=2, padding='valid'))\n",
        "        self.model.add(LSTM(units=self.h_n1, input_shape=(input_shape[1],1)))\n",
        "    \n",
        "        if type==2:\n",
        "            self.model.add(Dense(32))\n",
        "        self.model.add(Dense(1))\n",
        "        self.model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
        "    \n",
        "    def fit(self,x_train,y_train):\n",
        "        if self.scaler:\n",
        "            x_train = self.scaler.transform(x_train)\n",
        "            y_train = self.scaler.transform(y_train)\n",
        "            \n",
        "        # reshape the entry as a 3D matrix with samples, timestamps and lastly features\n",
        "        # instead of only samples and features as usual.\n",
        "        x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "        \n",
        "        self.model.fit(x_train, y_train,\n",
        "                        epochs=50,\n",
        "                        batch_size=128,\n",
        "                        verbose=0\n",
        "                      )\n",
        "\n",
        "    def predict(self, x_test):\n",
        "        if self.scaler:\n",
        "            x_test = self.scaler.transform(x_test)\n",
        "            \n",
        "        x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "        y_valid_pred = self.model.predict(x_test)\n",
        "        \n",
        "        if self.scaler:\n",
        "            y_valid_pred = self.scaler.transform(y_valid_pred)\n",
        "\n",
        "        return y_valid_pred.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU2anw2bhzcC"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixsT94Sst-K4"
      },
      "source": [
        "def create_models(entry_shape, scaler=None):\n",
        "    # SVR\n",
        "    svr = SVR(kernel='rbf', C=1, tol=1e-3)\n",
        "\n",
        "    # FFNN\n",
        "    ffnn = FFNN(entry_shape[1], scaler)\n",
        "\n",
        "    # LSTM1\n",
        "    lstm1 = PLSTM(entry_shape, 1, scaler)\n",
        "\n",
        "    # LSTM2\n",
        "    lstm2 = PLSTM(entry_shape, 2, scaler)\n",
        "\n",
        "    # LSTM3\n",
        "    lstm3 = PLSTM(entry_shape, 3, scaler)\n",
        "\n",
        "    # LSTM4\n",
        "    lstm4 = PLSTM(entry_shape, 4, scaler)\n",
        "\n",
        "    # CNN-LSTM1\n",
        "    cnnlstm1 = CNNLSTM(entry_shape, 1, scaler)\n",
        "\n",
        "    # CNN-LSTM2\n",
        "    cnnlstm2 = CNNLSTM(entry_shape, 2, scaler)\n",
        "\n",
        "    labels = [\"SVR\", \"FFNN\", \"LSTM1\", \"LSTM2\", \"LSTM3\", \"LSTM4\", \"CNN-LSTM1\", \"CNN-LSTM2\"]\n",
        "    models = [svr, ffnn, lstm1, lstm2, lstm3, lstm4, cnnlstm1, cnnlstm2]\n",
        "\n",
        "    return labels, models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1LV-V2lt-K4"
      },
      "source": [
        "## Rolling window approach\n",
        "The paper states that in order to predict the next day gold price, the model uses the $n$ past days gold prince, where $n$ stands for the time horizon used. Thus to generate a dataset with this specifications, we will use a rolling window algorithm to generate a window of features to a window of labels ( with in this case is equal to 1). This rolling window procedure works as follows:\n",
        "\n",
        "Features: $[n1, n2, n3, n4, n5]$ -> Label $[n6]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzUadvLWFrcY"
      },
      "source": [
        "Converts an array into a matrix with size (n_windows, window size)\n",
        "- col1   = 1:step:n - width + 1;\n",
        "- row1   = 0:width - 1;\n",
        "- index  = col1.' + row1;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyVWBYZJt-K4"
      },
      "source": [
        "def rolling_window_mtx(x, window_size):\n",
        "        \"\"\"Compute all overlapping (rolling) observation windows over a vector \n",
        "            and return a matrix\n",
        "\n",
        "        Args:\n",
        "            x           : observation vector that is supposed to be split into\n",
        "                          overlapping windows\n",
        "            window_size : the target window size\n",
        "\n",
        "        Returns:\n",
        "\n",
        "            Window matrix with all windows as rows. That is, if n_windows is the\n",
        "            number of windows, the result has dimensions:\n",
        "\n",
        "            (n_windows, window_size)\n",
        "\n",
        "        \"\"\"\n",
        "        if window_size < 1:\n",
        "            raise ValueError(\"`window_size` must be at least 1.\")\n",
        "        if window_size > x.shape[-1]:\n",
        "            raise ValueError(\"`window_size` is too long.\")\n",
        "\n",
        "        \n",
        "        shape = x.shape[:-1] + (x.shape[-1] - window_size + 1, window_size)\n",
        "        strides = x.strides + (x.strides[-1],)\n",
        "\n",
        "        return np.lib.stride_tricks.as_strided(x, shape=shape, strides=strides)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qlx0Idet-K5"
      },
      "source": [
        "def generate_feat_labels_per_horizon(time_horizon, df, verbose=False):\n",
        "\n",
        "    # Get the feature and label to the prediction task \n",
        "    feature_mtx = rolling_window_mtx(df, time_horizon)[:-1]\n",
        "    label_mtx   = rolling_window_mtx(df[time_horizon:], 1)\n",
        "    index_mtx   = rolling_window_mtx(np.arange(len(df)), time_horizon)\n",
        "\n",
        "    if verbose:\n",
        "        # Now we have a set of windows of the real coordinate\n",
        "        # Lets take a look in one window\n",
        "        print(f\"\\n One feature window: \\n {feature_mtx[0]}\")\n",
        "        print(f\"\\n One label window: \\n {label_mtx[0]}\")\n",
        "        print(f\"\\n Original dataset: \\n {df[0:5]}\")\n",
        "\n",
        "    # For the classification task (if the gold values goes up or down)\n",
        "    # We need to get a window of size 2, and then calculate the difference\n",
        "    # If positive, the gold value went up.\n",
        "    class_label_mtx = rolling_window_mtx(df[time_horizon-1:], 2)\n",
        "    func = lambda x: True if x > 0 else False\n",
        "    class_func = np.vectorize(func)\n",
        "    class_label_mtx = class_func(np.diff(class_label_mtx).flatten()).reshape(len(class_label_mtx),1)\n",
        "   \n",
        "    if verbose:\n",
        "    \n",
        "        print(f\"\\n One window of class label (If tomorrow price is larger than today's price): \\n {class_label_mtx[0]}\")\n",
        "    \n",
        "    return feature_mtx, label_mtx, class_label_mtx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7KcEIlHt-K5"
      },
      "source": [
        "label_index_mtx = rolling_window_mtx(np.arange(len(df))[4:], 1)\n",
        "index_mtx   = rolling_window_mtx(np.arange(len(df)), 4)[:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txx98lFbt-K5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f12952d5-c6b8-431b-c7b4-6706f8d565a5"
      },
      "source": [
        "train_idx = lastday_2017 - 4\n",
        "index_mtx[train_idx], label_index_mtx[train_idx]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1003, 1004, 1005, 1006]), array([1007]))"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqOPwCNTt-K6"
      },
      "source": [
        "## Normalizing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7_khhE4t-K6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03e5e252-3acd-4688-a310-d959604ea835"
      },
      "source": [
        "df = df.reshape(len(df),1)\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "scaler.fit(df)\n",
        "df = df.flatten()\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.08707235, 7.0936538 , 7.10799857, ..., 7.18841274, 7.18212409,\n",
              "       7.18182009])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eslwnt9mDen2"
      },
      "source": [
        "## Training the models for entries 4, 6 and 9 (days)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNqowxfRt-K6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f15ef418-6eba-4030-83e5-c202e4b94e04"
      },
      "source": [
        "entries = [4, 6, 9]\n",
        "models = []\n",
        "labels = []\n",
        "history = []\n",
        "for entry in entries:\n",
        "    #Creating dataset\n",
        "    feature_mtx, label_mtx, class_label_mtx = generate_feat_labels_per_horizon(entry, df)\n",
        "    print(feature_mtx, label_mtx, class_label_mtx)\n",
        "    scaler_input = MinMaxScaler(feature_range=(-1, 1))\n",
        "    print(scaler_input)\n",
        "    scaler_input.fit(feature_mtx)\n",
        "    scaler_output = MinMaxScaler(feature_range=(-1, 1))\n",
        "    print(scaler_output)\n",
        "    scaler_output.fit(label_mtx)\n",
        "    train_idx = lastday_2017 - entry\n",
        "    train_x = feature_mtx[:train_idx]\n",
        "    train_y = label_mtx[:train_idx]\n",
        "    print(\"Training X shape: \",train_x.shape)\n",
        "    print(\"Training Y shape: \",train_y.shape)\n",
        "    tmp_labels, tmp_models = create_models(train_x.shape)#, scaler)\n",
        "    for i in range(len(tmp_models)):\n",
        "        print(tmp_labels[i])\n",
        "        tmp_models[i].fit(train_x, train_y)\n",
        "    models.append(tmp_models)\n",
        "    labels.append(tmp_labels)\n",
        "    print(\"\\n=========================================================================\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7.08707235 7.0936538  7.10799857 7.11704332]\n",
            " [7.0936538  7.10799857 7.11704332 7.12230202]\n",
            " [7.10799857 7.11704332 7.12230202 7.11273486]\n",
            " ...\n",
            " [7.20682228 7.20228883 7.19593723 7.1902238 ]\n",
            " [7.20228883 7.19593723 7.1902238  7.18841274]\n",
            " [7.19593723 7.1902238  7.18841274 7.18212409]] [[7.12230202]\n",
            " [7.11273486]\n",
            " [7.11134901]\n",
            " ...\n",
            " [7.18841274]\n",
            " [7.18212409]\n",
            " [7.18182009]] [[ True]\n",
            " [False]\n",
            " [False]\n",
            " ...\n",
            " [False]\n",
            " [False]\n",
            " [False]]\n",
            "MinMaxScaler(feature_range=(-1, 1))\n",
            "MinMaxScaler(feature_range=(-1, 1))\n",
            "Training X shape:  (1003, 4)\n",
            "Training Y shape:  (1003, 1)\n",
            "SVR\n",
            "FFNN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM1\n",
            "LSTM2\n",
            "LSTM3\n",
            "LSTM4\n",
            "CNN-LSTM1\n",
            "CNN-LSTM2\n",
            "\n",
            "=========================================================================\n",
            "\n",
            "[[7.08707235 7.0936538  7.10799857 7.11704332 7.12230202 7.11273486]\n",
            " [7.0936538  7.10799857 7.11704332 7.12230202 7.11273486 7.11134901]\n",
            " [7.10799857 7.11704332 7.12230202 7.11273486 7.11134901 7.11882625]\n",
            " ...\n",
            " [7.20637729 7.20303343 7.20682228 7.20228883 7.19593723 7.1902238 ]\n",
            " [7.20303343 7.20682228 7.20228883 7.19593723 7.1902238  7.18841274]\n",
            " [7.20682228 7.20228883 7.19593723 7.1902238  7.18841274 7.18212409]] [[7.11134901]\n",
            " [7.11882625]\n",
            " [7.1313787 ]\n",
            " ...\n",
            " [7.18841274]\n",
            " [7.18212409]\n",
            " [7.18182009]] [[False]\n",
            " [ True]\n",
            " [ True]\n",
            " ...\n",
            " [False]\n",
            " [False]\n",
            " [False]]\n",
            "MinMaxScaler(feature_range=(-1, 1))\n",
            "MinMaxScaler(feature_range=(-1, 1))\n",
            "Training X shape:  (1001, 6)\n",
            "Training Y shape:  (1001, 1)\n",
            "SVR\n",
            "FFNN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM1\n",
            "LSTM2\n",
            "LSTM3\n",
            "LSTM4\n",
            "CNN-LSTM1\n",
            "CNN-LSTM2\n",
            "\n",
            "=========================================================================\n",
            "\n",
            "[[7.08707235 7.0936538  7.10799857 ... 7.11134901 7.11882625 7.1313787 ]\n",
            " [7.0936538  7.10799857 7.11704332 ... 7.11882625 7.1313787  7.13169851]\n",
            " [7.10799857 7.11704332 7.12230202 ... 7.1313787  7.13169851 7.12536352]\n",
            " ...\n",
            " [7.20874833 7.19736052 7.20117088 ... 7.20228883 7.19593723 7.1902238 ]\n",
            " [7.19736052 7.20117088 7.20637729 ... 7.19593723 7.1902238  7.18841274]\n",
            " [7.20117088 7.20637729 7.20303343 ... 7.1902238  7.18841274 7.18212409]] [[7.13169851]\n",
            " [7.12536352]\n",
            " [7.12230202]\n",
            " ...\n",
            " [7.18841274]\n",
            " [7.18212409]\n",
            " [7.18182009]] [[ True]\n",
            " [False]\n",
            " [False]\n",
            " ...\n",
            " [False]\n",
            " [False]\n",
            " [False]]\n",
            "MinMaxScaler(feature_range=(-1, 1))\n",
            "MinMaxScaler(feature_range=(-1, 1))\n",
            "Training X shape:  (998, 9)\n",
            "Training Y shape:  (998, 1)\n",
            "SVR\n",
            "FFNN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM1\n",
            "LSTM2\n",
            "LSTM3\n",
            "LSTM4\n",
            "CNN-LSTM1\n",
            "CNN-LSTM2\n",
            "\n",
            "=========================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oomg0KGlt-K7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43b35bd6-b516-4bb8-9954-e7bf5392796e"
      },
      "source": [
        "models = np.ravel(models)\n",
        "labels = np.ravel(labels)\n",
        "print(len(models))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHDn9rQhDXQZ"
      },
      "source": [
        "## Helper functions for prediction and Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pS6PDdGt-K7"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sb\n",
        "\n",
        "def classification_pred(y):\n",
        "    preds = []\n",
        "    for i in range(1, len(y)):\n",
        "        last_y = y[i - 1]\n",
        "        curr_y = y[i]\n",
        "        preds.append(curr_y - last_y > 0.0 )\n",
        "    return np.array(preds)\n",
        "\n",
        "# Metric functions\n",
        "def get_metrics(y, pred_y):\n",
        "    y_classification = classification_pred(y)\n",
        "    y_pred_classification = classification_pred(pred_y)\n",
        "    \n",
        "    fpr, tpr, thresholds = roc_curve(y_classification, y_pred_classification)\n",
        "    auc_value = auc(fpr, tpr)\n",
        "\n",
        "    \n",
        "    tp = 0\n",
        "    tn = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "    \n",
        "    for i in range(len(y_classification)):\n",
        "        is_y_pred_up = y_pred_classification[i]\n",
        "        is_y_up = y_classification[i][0]\n",
        "\n",
        "        if is_y_pred_up and is_y_up:\n",
        "            tp += 1\n",
        "        elif is_y_pred_up and not is_y_up:\n",
        "            fp += 1\n",
        "        elif not is_y_pred_up and not is_y_up:\n",
        "            tn += 1\n",
        "        else:\n",
        "            fn += 1\n",
        "    print(\"Classification report\\n\",classification_report(y_classification, y_pred_classification))\n",
        "    return tp, tn, fp, fn, auc_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN4PoG_LDQ-G"
      },
      "source": [
        "## List of metrics for all the models for entries 4, 6 and 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aOSMOvCt-K8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13791ca6-c336-4a45-9b9c-3b04ffc20049"
      },
      "source": [
        "# Testing models\n",
        "index_model = 0\n",
        "for entry in entries:\n",
        "    print (\"# Entries: \", entry)\n",
        "    feature_mtx, label_mtx, class_label_mtx = generate_feat_labels_per_horizon(entry, df)\n",
        "    scaler_input = MinMaxScaler(feature_range=(-1, 1))\n",
        "    scaler_input.fit(feature_mtx)\n",
        "    train_idx = lastday_2017 - entry\n",
        "    test_x = feature_mtx[train_idx:]\n",
        "    test_y = label_mtx[train_idx:]\n",
        "    \n",
        "    model_list = []\n",
        "    MAE_list = []\n",
        "    RMSE_list = []\n",
        "    ACC_list = []\n",
        "    AUC_list = []\n",
        "    SEN_list = []\n",
        "    SPE_list = []\n",
        "    \n",
        "    for i in range(index_model, index_model+8):\n",
        "        test_y_estimative = models[i].predict(test_x)\n",
        "        tp, tn, fp, fn, auc_value = get_metrics(test_y, test_y_estimative)\n",
        "        \n",
        "        model_list.append(labels[i])\n",
        "        MAE_list.append(mean_absolute_error(test_y, test_y_estimative))\n",
        "        RMSE_list.append(mean_squared_error(test_y, test_y_estimative, squared=True))\n",
        "        ACC_list.append(((tp + tn) / (tp + tn + fp + fn))*100)\n",
        "        AUC_list.append(auc_value)\n",
        "        SEN_list.append(tp / (tp + fn))\n",
        "        SPE_list.append(tn / (tn + fp))\n",
        "        \n",
        "    df_print = pd.DataFrame(list(zip(model_list, MAE_list,RMSE_list,ACC_list,AUC_list,SEN_list, SPE_list)),\n",
        "           columns =['Model', 'MAE', 'RMSE', 'ACC (%)', 'AUC', 'SPEN', 'SPE'])\n",
        "    df_print = df_print.sort_values(by=['ACC (%)'], ascending=False)\n",
        "    print(df_print)\n",
        "    print(\"\\n==============================================================================\\n\")\n",
        "        \n",
        "    index_model += 8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Entries:  4\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.39      0.38      0.39        34\n",
            "        True       0.47      0.49      0.48        39\n",
            "\n",
            "    accuracy                           0.44        73\n",
            "   macro avg       0.43      0.43      0.43        73\n",
            "weighted avg       0.44      0.44      0.44        73\n",
            "\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.40      0.41      0.41        34\n",
            "        True       0.47      0.46      0.47        39\n",
            "\n",
            "    accuracy                           0.44        73\n",
            "   macro avg       0.44      0.44      0.44        73\n",
            "weighted avg       0.44      0.44      0.44        73\n",
            "\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.36      0.38      0.37        34\n",
            "        True       0.43      0.41      0.42        39\n",
            "\n",
            "    accuracy                           0.40        73\n",
            "   macro avg       0.40      0.40      0.40        73\n",
            "weighted avg       0.40      0.40      0.40        73\n",
            "\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.33      0.35      0.34        34\n",
            "        True       0.41      0.38      0.39        39\n",
            "\n",
            "    accuracy                           0.37        73\n",
            "   macro avg       0.37      0.37      0.37        73\n",
            "weighted avg       0.37      0.37      0.37        73\n",
            "\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.33      0.32      0.33        34\n",
            "        True       0.42      0.44      0.43        39\n",
            "\n",
            "    accuracy                           0.38        73\n",
            "   macro avg       0.38      0.38      0.38        73\n",
            "weighted avg       0.38      0.38      0.38        73\n",
            "\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.38      0.35      0.36        34\n",
            "        True       0.46      0.49      0.48        39\n",
            "\n",
            "    accuracy                           0.42        73\n",
            "   macro avg       0.42      0.42      0.42        73\n",
            "weighted avg       0.42      0.42      0.42        73\n",
            "\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.41      0.47      0.44        34\n",
            "        True       0.47      0.41      0.44        39\n",
            "\n",
            "    accuracy                           0.44        73\n",
            "   macro avg       0.44      0.44      0.44        73\n",
            "weighted avg       0.44      0.44      0.44        73\n",
            "\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.41      0.47      0.44        34\n",
            "        True       0.47      0.41      0.44        39\n",
            "\n",
            "    accuracy                           0.44        73\n",
            "   macro avg       0.44      0.44      0.44        73\n",
            "weighted avg       0.44      0.44      0.44        73\n",
            "\n",
            "       Model       MAE      RMSE    ACC (%)       AUC      SPEN       SPE\n",
            "0        SVR  0.065454  0.004346  43.835616  0.434766  0.487179  0.382353\n",
            "1       FFNN  3.018049  9.108672  43.835616  0.436652  0.461538  0.411765\n",
            "6  CNN-LSTM1  0.064450  0.004224  43.835616  0.440422  0.410256  0.470588\n",
            "7  CNN-LSTM2  0.057434  0.003363  43.835616  0.440422  0.410256  0.470588\n",
            "5      LSTM4  0.069833  0.004958  42.465753  0.420060  0.487179  0.352941\n",
            "2      LSTM1  0.064933  0.004296  39.726027  0.396305  0.410256  0.382353\n",
            "4      LSTM3  0.075311  0.005755  38.356164  0.379713  0.435897  0.323529\n",
            "3      LSTM2  0.058633  0.003516  36.986301  0.368778  0.384615  0.352941\n",
            "\n",
            "==============================================================================\n",
            "\n",
            "# Entries:  6\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.42      0.38      0.40        34\n",
            "        True       0.50      0.54      0.52        39\n",
            "\n",
            "    accuracy                           0.47        73\n",
            "   macro avg       0.46      0.46      0.46        73\n",
            "weighted avg       0.46      0.47      0.46        73\n",
            "\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.43      0.47      0.45        34\n",
            "        True       0.50      0.46      0.48        39\n",
            "\n",
            "    accuracy                           0.47        73\n",
            "   macro avg       0.47      0.47      0.47        73\n",
            "weighted avg       0.47      0.47      0.47        73\n",
            "\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.50      0.50      0.50        34\n",
            "        True       0.56      0.56      0.56        39\n",
            "\n",
            "    accuracy                           0.53        73\n",
            "   macro avg       0.53      0.53      0.53        73\n",
            "weighted avg       0.53      0.53      0.53        73\n",
            "\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.52      0.47      0.49        34\n",
            "        True       0.57      0.62      0.59        39\n",
            "\n",
            "    accuracy                           0.55        73\n",
            "   macro avg       0.54      0.54      0.54        73\n",
            "weighted avg       0.55      0.55      0.55        73\n",
            "\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.48      0.41      0.44        34\n",
            "        True       0.55      0.62      0.58        39\n",
            "\n",
            "    accuracy                           0.52        73\n",
            "   macro avg       0.51      0.51      0.51        73\n",
            "weighted avg       0.52      0.52      0.52        73\n",
            "\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.47      0.44      0.45        34\n",
            "        True       0.54      0.56      0.55        39\n",
            "\n",
            "    accuracy                           0.51        73\n",
            "   macro avg       0.50      0.50      0.50        73\n",
            "weighted avg       0.50      0.51      0.51        73\n",
            "\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.41      0.47      0.44        34\n",
            "        True       0.47      0.41      0.44        39\n",
            "\n",
            "    accuracy                           0.44        73\n",
            "   macro avg       0.44      0.44      0.44        73\n",
            "weighted avg       0.44      0.44      0.44        73\n",
            "\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.38      0.44      0.41        34\n",
            "        True       0.44      0.38      0.41        39\n",
            "\n",
            "    accuracy                           0.41        73\n",
            "   macro avg       0.41      0.41      0.41        73\n",
            "weighted avg       0.41      0.41      0.41        73\n",
            "\n",
            "       Model       MAE      RMSE    ACC (%)       AUC      SPEN       SPE\n",
            "3      LSTM2  0.067590  0.004647  54.794521  0.542986  0.615385  0.470588\n",
            "2      LSTM1  0.075690  0.005813  53.424658  0.532051  0.564103  0.500000\n",
            "4      LSTM3  0.074039  0.005565  52.054795  0.513575  0.615385  0.411765\n",
            "5      LSTM4  0.079264  0.006366  50.684932  0.502640  0.564103  0.441176\n",
            "0        SVR  0.064272  0.004198  46.575342  0.460407  0.538462  0.382353\n",
            "1       FFNN  3.005516  9.033265  46.575342  0.466063  0.461538  0.470588\n",
            "6  CNN-LSTM1  0.059707  0.003635  43.835616  0.440422  0.410256  0.470588\n",
            "7  CNN-LSTM2  0.063534  0.004108  41.095890  0.412896  0.384615  0.441176\n",
            "\n",
            "==============================================================================\n",
            "\n",
            "# Entries:  9\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.40      0.41      0.41        34\n",
            "        True       0.47      0.46      0.47        39\n",
            "\n",
            "    accuracy                           0.44        73\n",
            "   macro avg       0.44      0.44      0.44        73\n",
            "weighted avg       0.44      0.44      0.44        73\n",
            "\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.50      0.50      0.50        34\n",
            "        True       0.56      0.56      0.56        39\n",
            "\n",
            "    accuracy                           0.53        73\n",
            "   macro avg       0.53      0.53      0.53        73\n",
            "weighted avg       0.53      0.53      0.53        73\n",
            "\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.44      0.47      0.46        34\n",
            "        True       0.51      0.49      0.50        39\n",
            "\n",
            "    accuracy                           0.48        73\n",
            "   macro avg       0.48      0.48      0.48        73\n",
            "weighted avg       0.48      0.48      0.48        73\n",
            "\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.32      0.35      0.34        34\n",
            "        True       0.39      0.36      0.37        39\n",
            "\n",
            "    accuracy                           0.36        73\n",
            "   macro avg       0.36      0.36      0.36        73\n",
            "weighted avg       0.36      0.36      0.36        73\n",
            "\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.44      0.47      0.46        34\n",
            "        True       0.51      0.49      0.50        39\n",
            "\n",
            "    accuracy                           0.48        73\n",
            "   macro avg       0.48      0.48      0.48        73\n",
            "weighted avg       0.48      0.48      0.48        73\n",
            "\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.36      0.38      0.37        34\n",
            "        True       0.43      0.41      0.42        39\n",
            "\n",
            "    accuracy                           0.40        73\n",
            "   macro avg       0.40      0.40      0.40        73\n",
            "weighted avg       0.40      0.40      0.40        73\n",
            "\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.43      0.44      0.43        34\n",
            "        True       0.50      0.49      0.49        39\n",
            "\n",
            "    accuracy                           0.47        73\n",
            "   macro avg       0.46      0.46      0.46        73\n",
            "weighted avg       0.47      0.47      0.47        73\n",
            "\n",
            "Classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.43      0.38      0.41        34\n",
            "        True       0.51      0.56      0.54        39\n",
            "\n",
            "    accuracy                           0.48        73\n",
            "   macro avg       0.47      0.47      0.47        73\n",
            "weighted avg       0.48      0.48      0.48        73\n",
            "\n",
            "       Model       MAE      RMSE    ACC (%)       AUC      SPEN       SPE\n",
            "1       FFNN  0.346766  0.120660  53.424658  0.532051  0.564103  0.500000\n",
            "2      LSTM1  0.072042  0.005270  47.945205  0.478884  0.487179  0.470588\n",
            "4      LSTM3  0.077048  0.006019  47.945205  0.478884  0.487179  0.470588\n",
            "7  CNN-LSTM2  0.068630  0.004787  47.945205  0.473228  0.564103  0.382353\n",
            "6  CNN-LSTM1  0.068055  0.004706  46.575342  0.464178  0.487179  0.441176\n",
            "0        SVR  0.063515  0.004104  43.835616  0.436652  0.461538  0.411765\n",
            "5      LSTM4  0.078318  0.006217  39.726027  0.396305  0.410256  0.382353\n",
            "3      LSTM2  0.077180  0.006040  35.616438  0.355958  0.358974  0.352941\n",
            "\n",
            "==============================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd05UA-lt-K8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1b54d24-5839-4c6c-dc29-0692d161fbd7"
      },
      "source": [
        "model_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SVR', 'FFNN', 'LSTM1', 'LSTM2', 'LSTM3', 'LSTM4', 'CNN-LSTM1', 'CNN-LSTM2']"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjYQ6Su2DIi2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}